{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import napari\n",
    "from FoodSeg103_data_handler import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create scribbles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the ground truths as batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "503 Server Error: Service Temporarily Unavailable for url: https://huggingface.co/api/datasets/EduardoPacheco/FoodSeg103",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\Beruf & Ausbildung\\Ausbildung\\22-08 MSC Bioinf\\24FS_Master Thesis\\02_scribble_datasets_tests\\01_create_scribbles_FoodSeg103.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/Beruf%20%26%20Ausbildung/Ausbildung/22-08%20MSC%20Bioinf/24FS_Master%20Thesis/02_scribble_datasets_tests/01_create_scribbles_FoodSeg103.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m img_nums \u001b[39m=\u001b[39m [\u001b[39m1792\u001b[39m] \u001b[39m#[n for n in range(0, 4900, 500)] #2750 #1234 #2314\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents/Beruf%20%26%20Ausbildung/Ausbildung/22-08%20MSC%20Bioinf/24FS_Master%20Thesis/02_scribble_datasets_tests/01_create_scribbles_FoodSeg103.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m gts \u001b[39m=\u001b[39m load_food_batch(img_nums, load_images\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/Beruf%20%26%20Ausbildung/Ausbildung/22-08%20MSC%20Bioinf/24FS_Master%20Thesis/02_scribble_datasets_tests/01_create_scribbles_FoodSeg103.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m num_imgs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(gts)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documents/Beruf%20%26%20Ausbildung/Ausbildung/22-08%20MSC%20Bioinf/24FS_Master%20Thesis/02_scribble_datasets_tests/01_create_scribbles_FoodSeg103.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTotal images: \u001b[39m\u001b[39m{\u001b[39;00mnum_imgs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Documents\\Beruf & Ausbildung\\Ausbildung\\22-08 MSC Bioinf\\24FS_Master Thesis\\02_scribble_datasets_tests\\FoodSeg103_data_handler.py:36\u001b[0m, in \u001b[0;36mload_food_batch\u001b[1;34m(img_num_list, load_images, load_gts)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_food_batch\u001b[39m(img_num_list: \u001b[39mlist\u001b[39m, load_images\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, load_gts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     33\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m    Load a batch of images and/or ground truths from the FoodSeg103 dataset.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mEduardoPacheco/FoodSeg103\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     37\u001b[0m     img_dict \u001b[39m=\u001b[39m {}\n\u001b[0;32m     38\u001b[0m     ground_truth_dict \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\roman\\anaconda3\\envs\\ilastik2\\lib\\site-packages\\datasets\\load.py:2556\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2551\u001b[0m verification_mode \u001b[39m=\u001b[39m VerificationMode(\n\u001b[0;32m   2552\u001b[0m     (verification_mode \u001b[39mor\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m save_infos \u001b[39melse\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS\n\u001b[0;32m   2553\u001b[0m )\n\u001b[0;32m   2555\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 2556\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[0;32m   2557\u001b[0m     path\u001b[39m=\u001b[39mpath,\n\u001b[0;32m   2558\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m   2559\u001b[0m     data_dir\u001b[39m=\u001b[39mdata_dir,\n\u001b[0;32m   2560\u001b[0m     data_files\u001b[39m=\u001b[39mdata_files,\n\u001b[0;32m   2561\u001b[0m     cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[0;32m   2562\u001b[0m     features\u001b[39m=\u001b[39mfeatures,\n\u001b[0;32m   2563\u001b[0m     download_config\u001b[39m=\u001b[39mdownload_config,\n\u001b[0;32m   2564\u001b[0m     download_mode\u001b[39m=\u001b[39mdownload_mode,\n\u001b[0;32m   2565\u001b[0m     revision\u001b[39m=\u001b[39mrevision,\n\u001b[0;32m   2566\u001b[0m     token\u001b[39m=\u001b[39mtoken,\n\u001b[0;32m   2567\u001b[0m     storage_options\u001b[39m=\u001b[39mstorage_options,\n\u001b[0;32m   2568\u001b[0m     trust_remote_code\u001b[39m=\u001b[39mtrust_remote_code,\n\u001b[0;32m   2569\u001b[0m     _require_default_config_name\u001b[39m=\u001b[39mname \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2570\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig_kwargs,\n\u001b[0;32m   2571\u001b[0m )\n\u001b[0;32m   2573\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   2574\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mc:\\Users\\roman\\anaconda3\\envs\\ilastik2\\lib\\site-packages\\datasets\\load.py:2228\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   2226\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   2227\u001b[0m     download_config\u001b[39m.\u001b[39mstorage_options\u001b[39m.\u001b[39mupdate(storage_options)\n\u001b[1;32m-> 2228\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[0;32m   2229\u001b[0m     path,\n\u001b[0;32m   2230\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   2231\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m   2232\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m   2233\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[0;32m   2234\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[0;32m   2235\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   2236\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code,\n\u001b[0;32m   2237\u001b[0m     _require_default_config_name\u001b[39m=\u001b[39;49m_require_default_config_name,\n\u001b[0;32m   2238\u001b[0m     _require_custom_configs\u001b[39m=\u001b[39;49m\u001b[39mbool\u001b[39;49m(config_kwargs),\n\u001b[0;32m   2239\u001b[0m )\n\u001b[0;32m   2240\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   2241\u001b[0m builder_kwargs \u001b[39m=\u001b[39m dataset_module\u001b[39m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[1;32mc:\\Users\\roman\\anaconda3\\envs\\ilastik2\\lib\\site-packages\\datasets\\load.py:1879\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1874\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e1, \u001b[39mFileNotFoundError\u001b[39;00m):\n\u001b[0;32m   1875\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1876\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a dataset script at \u001b[39m\u001b[39m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[39m}\u001b[39;00m\u001b[39m or any data file in the same directory. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1877\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m on the Hugging Face Hub either: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(e1)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me1\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1878\u001b[0m                 ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1879\u001b[0m             \u001b[39mraise\u001b[39;00m e1 \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1880\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1882\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a dataset script at \u001b[39m\u001b[39m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[39m}\u001b[39;00m\u001b[39m or any data file in the same directory.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1883\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\roman\\anaconda3\\envs\\ilastik2\\lib\\site-packages\\datasets\\load.py:1824\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1819\u001b[0m         \u001b[39mraise\u001b[39;00m DatasetNotFoundError(\n\u001b[0;32m   1820\u001b[0m             msg\n\u001b[0;32m   1821\u001b[0m             \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m. If the dataset is private or gated, make sure to log in with `huggingface-cli login` or visit the dataset page at https://huggingface.co/datasets/\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m to ask for access.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1822\u001b[0m         )\n\u001b[0;32m   1823\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1824\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m   1825\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39min\u001b[39;00m [sibling\u001b[39m.\u001b[39mrfilename \u001b[39mfor\u001b[39;00m sibling \u001b[39min\u001b[39;00m dataset_info\u001b[39m.\u001b[39msiblings]:  \u001b[39m# contains a dataset script\u001b[39;00m\n\u001b[0;32m   1826\u001b[0m     fs \u001b[39m=\u001b[39m HfFileSystem(endpoint\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mHF_ENDPOINT, token\u001b[39m=\u001b[39mdownload_config\u001b[39m.\u001b[39mtoken)\n",
      "File \u001b[1;32mc:\\Users\\roman\\anaconda3\\envs\\ilastik2\\lib\\site-packages\\datasets\\load.py:1797\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1795\u001b[0m hf_api \u001b[39m=\u001b[39m HfApi(config\u001b[39m.\u001b[39mHF_ENDPOINT)\n\u001b[0;32m   1796\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1797\u001b[0m     dataset_info \u001b[39m=\u001b[39m hf_api\u001b[39m.\u001b[39;49mdataset_info(\n\u001b[0;32m   1798\u001b[0m         repo_id\u001b[39m=\u001b[39;49mpath,\n\u001b[0;32m   1799\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   1800\u001b[0m         token\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mtoken,\n\u001b[0;32m   1801\u001b[0m         timeout\u001b[39m=\u001b[39;49m\u001b[39m100.0\u001b[39;49m,\n\u001b[0;32m   1802\u001b[0m     )\n\u001b[0;32m   1803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# noqa catch any exception of hf_hub and consider that the dataset doesn't exist\u001b[39;00m\n\u001b[0;32m   1804\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m   1805\u001b[0m         e,\n\u001b[0;32m   1806\u001b[0m         (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1810\u001b[0m         ),\n\u001b[0;32m   1811\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\roman\\anaconda3\\envs\\ilastik2\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    117\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\roman\\anaconda3\\envs\\ilastik2\\lib\\site-packages\\huggingface_hub\\hf_api.py:2291\u001b[0m, in \u001b[0;36mHfApi.dataset_info\u001b[1;34m(self, repo_id, revision, timeout, files_metadata, token)\u001b[0m\n\u001b[0;32m   2288\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mblobs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2290\u001b[0m r \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39mget(path, headers\u001b[39m=\u001b[39mheaders, timeout\u001b[39m=\u001b[39mtimeout, params\u001b[39m=\u001b[39mparams)\n\u001b[1;32m-> 2291\u001b[0m hf_raise_for_status(r)\n\u001b[0;32m   2292\u001b[0m data \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n\u001b[0;32m   2293\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetInfo(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\roman\\anaconda3\\envs\\ilastik2\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:371\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[39mraise\u001b[39;00m HfHubHTTPError(message, response\u001b[39m=\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[39m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[1;32m--> 371\u001b[0m \u001b[39mraise\u001b[39;00m HfHubHTTPError(\u001b[39mstr\u001b[39m(e), response\u001b[39m=\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m: 503 Server Error: Service Temporarily Unavailable for url: https://huggingface.co/api/datasets/EduardoPacheco/FoodSeg103"
     ]
    }
   ],
   "source": [
    "img_nums = [1792] #[n for n in range(0, 4900, 500)] #2750 #1234 #2314\n",
    "gts = load_food_batch(img_nums, load_images=False)[1]\n",
    "num_imgs = len(gts)\n",
    "print(f\"Total images: {num_imgs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and filter for resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resol = {im_num: np.prod(gt.shape) for im_num, gt in gts.items()}\n",
    "\n",
    "# Check for images with resolution over a certain threshold\n",
    "thresh = 250_000\n",
    "print(\"Resolutions:\")\n",
    "for im_num, r in resol.items(): print(f\"{im_num:4d}: {r:9,d} pixels{' (!)' if r > thresh else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out those images\n",
    "gts = {im_num: gt for im_num, gt in gts.items() if resol[im_num] <= thresh}\n",
    "num_imgs = len(gts)\n",
    "print(f\"Images with resolution under {thresh:,d}: {num_imgs}\")\n",
    "resol_new = {im_num: np.prod(gt.shape) for im_num, gt in gts.items()}\n",
    "for im_num, r in resol_new.items(): print(f\"{im_num:4d}: {r:7,d} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define scribbles parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which scribbles to create\n",
    "bins = [0.05]#[0.05, 0.3, 1.5]\n",
    "suff = [\"w3\"] #standing for width 3\n",
    "sq_scaling = 100\n",
    "scribble_width = 3\n",
    "scribbles_seed = 1\n",
    "\n",
    "# Where to save the scribbles\n",
    "folder_path = \"./FoodSeg103_results/data/run02\"\n",
    "\n",
    "save_res = False\n",
    "show_res = True\n",
    "print_steps = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop and create scribbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG 1792: bin 0.05, suff w3\n",
      "CLASS 1:\n",
      "sk_max_pix: 12.33, sq_size: 44, sk_pix_range: (12, 88)\n",
      "   prim_sk_squares pix: 12 = 0.02%\n",
      "Adjusting square size and range to 22 (11, 88)\n",
      "Adjusting square size and range to 11 (5, 88)\n",
      "   sec_sk_squares pix: 11 = 0.01%\n",
      "lines_max_pix: 12.33, line_pix_range: (12, 88)\n",
      "   lines pix: 12 = 0.02%\n",
      "TOTAL pix: 35 = 0.05%\n",
      "CLASS 90:\n",
      "sk_max_pix: 3.11, sq_size: 44, sk_pix_range: (3, 88)\n",
      "Adjusting square size and range to 22 (3, 88)\n",
      "Adjusting square size and range to 11 (3, 88)\n",
      "Adjusting square size and range to 5 (2, 88)\n",
      "Adjusting square size and range to 2 (1, 88)\n",
      "   prim_sk_squares pix: 3 = 0.02%\n",
      "Adjusting square size and range to 22 (3, 88)\n",
      "Adjusting square size and range to 11 (3, 88)\n",
      "Adjusting square size and range to 5 (2, 88)\n",
      "Adjusting square size and range to 2 (1, 88)\n",
      "   sec_sk_squares pix: 3 = 0.02%\n",
      "lines_max_pix: 3.11, line_pix_range: (3, 88)\n",
      "Adjusting line range to (1, 176)\n",
      "Adjusting distance to edge to 14\n",
      "Adjusting distance to edge to 21\n",
      "   lines pix: 3 = 0.02%\n",
      "TOTAL pix: 9 = 0.05%\n",
      "CLASS 51:\n",
      "sk_max_pix: 2.83, sq_size: 44, sk_pix_range: (2, 88)\n",
      "Adjusting square size and range to 22 (2, 88)\n",
      "Adjusting square size and range to 11 (2, 88)\n",
      "Adjusting square size and range to 5 (2, 88)\n",
      "Adjusting square size and range to 2 (1, 88)\n",
      "   prim_sk_squares pix: 2 = 0.01%\n",
      "Adjusting square size and range to 22 (2, 88)\n",
      "Adjusting square size and range to 11 (2, 88)\n",
      "Adjusting square size and range to 5 (2, 88)\n",
      "Adjusting square size and range to 2 (1, 88)\n",
      "   sec_sk_squares pix: 2 = 0.01%\n",
      "lines_max_pix: 2.83, line_pix_range: (2, 88)\n",
      "   lines pix: 2 = 0.01%\n",
      "TOTAL pix: 6 = 0.04%\n",
      "CLASS 25:\n",
      "sk_max_pix: 14.49, sq_size: 44, sk_pix_range: (14, 88)\n",
      "Adjusting square size and range to 22 (11, 88)\n",
      "   prim_sk_squares pix: 14 = 0.02%\n",
      "Adjusting square size and range to 22 (11, 88)\n",
      "Adjusting square size and range to 11 (5, 88)\n",
      "   sec_sk_squares pix: 11 = 0.01%\n",
      "lines_max_pix: 14.49, line_pix_range: (14, 88)\n",
      "Adjusting line range to (7, 176)\n",
      "Adjusting line range to (3, 352)\n",
      "Adjusting line range to (1, 704)\n",
      "Adjusting distance to edge to 76\n",
      "Adjusting distance to edge to 95\n",
      "Adjusting distance to edge to 103\n"
     ]
    }
   ],
   "source": [
    "percentages = {}\n",
    "for bin in bins:\n",
    "    percentages[bin] = []\n",
    "    for img_num, gt in gts.items():\n",
    "        for s in suff:\n",
    "            np.random.seed(scribbles_seed)\n",
    "            print(f\"IMG {img_num}: bin {bin}, suff {s}\")\n",
    "            scribbles, perc_labelled = create_food_scribble(gt, folder_path, img_num, bin=bin, sq_scaling=sq_scaling, mode=\"all\",\n",
    "                                                            save_res=save_res, suff=s, show_res=show_res, image=None, print_steps=print_steps, scribble_width=scribble_width)\n",
    "            percentages[bin].append(perc_labelled)\n",
    "            print(f\"Annotation percentage: {perc_labelled:2.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009561643276762403"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(scribbles>0) / np.prod(scribbles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick report of labelling percentages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelled percentage in bin 0.3: mean = 0.9562, std = 0.0000, range = 0.9562 - 0.9562\n"
     ]
    }
   ],
   "source": [
    "for bin, perc_list in percentages.items():\n",
    "    print(f\"labelled percentage in bin {bin}: mean = {np.mean(perc_list):.4f}, std = {np.std(perc_list):.4f}, range = {np.min(perc_list):.4f} - {np.max(perc_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the last created scribble with its ground truth, and all ground truths (optionally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = napari.Viewer()\n",
    "v.add_labels(gt, name=\"Ground Truth\")\n",
    "v.add_labels(scribbles, name=\"Scribbles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in gts:\n",
    "    v.add_labels(gts[g], name=f\"GT {g}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilastik2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
