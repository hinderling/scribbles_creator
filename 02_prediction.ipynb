{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\roman\\anaconda3\\envs\\ilastik2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import napari\n",
    "from PIL import Image\n",
    "\n",
    "from scribbles_creator import *\n",
    "from cellpose_data_handler import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define where the images are located and what data to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./cellpose_train_imgs/24-03-08_pred01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"all\"\n",
    "bins = [0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1]\n",
    "all_suff = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\"]\n",
    "suff = all_suff[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create predictions/segmentations on the cellpose dataset (with self-created scribbles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the convpaint parameters\n",
    "# layer_list = [0] # layers to use for convpaint (depending on the model chosen)\n",
    "# scalings = [1, 2] # scalings for convpaint (downscaling the image)\n",
    "# model=\"vgg16\" # 'vgg16', 'efficient_netb0', 'single_layer_vgg16', 'single_layer_vgg16_rgb', 'dino_vits16'\n",
    "# random_state = None # seed used for random forest classifier\n",
    "\n",
    "# # Predictions\n",
    "# for img_num in range(0, 10):\n",
    "#     for bin in bins:\n",
    "#         for s in suff:\n",
    "#             print(f\"IMG {img_num}: {bin}_{s}\")\n",
    "#             pred_cellpose_convpaint(folder_path, img_num, mode=mode, bin=bin, suff=s, layer_list=layer_list, scalings=scalings, model=model, random_state=random_state, save_res=True, show_res=False)\n",
    "#             pred_cellpose_ilastik(folder_path, img_num, mode=mode, bin=bin, suff=s, save_res=True, show_res=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same cell but for testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG 500: 0.1_a\n",
      "Active channels: R=False, G=True, B=False --> Removed 2 channel(s) --> shape: (225, 225)\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"./results/data/pred05_run02\"\n",
    "# folder_path = \"./cellpose_train_imgs\"\n",
    "\n",
    "mode = \"all\"\n",
    "bins = [0.1]#, 0.025, 0.05, 0.1, 0.25, 0.5, 1]\n",
    "all_suff = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\"]\n",
    "suff = all_suff[:1]\n",
    "\n",
    "# Define the convpaint parameters\n",
    "layer_list = [0] # layers to use for convpaint (depending on the model chosen)\n",
    "scalings = [1, 2] # scalings for convpaint (downscaling the image)\n",
    "model=\"single_layer_vgg16\" # 'vgg16', 'efficient_netb0', 'single_layer_vgg16', 'single_layer_vgg16_rgb', 'dino_vits16'\n",
    "random_state = 123 # seed used for random forest classifier\n",
    "\n",
    "# Predictions\n",
    "for img_num in [130]:#(0,189):#range(0, 10):\n",
    "    for bin in [0.1]: #bins:\n",
    "        for s in [\"a\"]:#suff:\n",
    "            print(f\"IMG {img_num}: {bin}_{s}\")\n",
    "            # get_cellpose_img_data(folder_path, img_num, load_img=True, load_gt=False, load_scribbles=False, mode=mode, bin=bin, suff=s, load_pred=False, pred_tag=\"convpaint\")\n",
    "            # pred_cellpose_convpaint(folder_path, img_num, mode=mode, bin=bin, suff=s, layer_list=layer_list, scalings=scalings, model=model, random_state=random_state, save_res=False, show_res=True)\n",
    "            pred_cellpose_ilastik(folder_path, img_num, mode=mode, bin=bin, suff=s, save_res=False, show_res=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing VGG16 options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG 500: bin 0.1, scalings [1, 2], layers [0]\n",
      "Active channels: R=False, G=True, B=False --> Removed 2 channel(s) --> shape: (225, 225)\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"./results/data/pred05_run02\"\n",
    "# folder_path = \"./cellpose_train_imgs\"\n",
    "\n",
    "mode = \"all\"\n",
    "bins = [0.1]#, 0.025, 0.05, 0.1, 0.25, 0.5, 1]\n",
    "all_suff = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\"]\n",
    "suff = all_suff[:1]\n",
    "s = \"a\"\n",
    "\n",
    "# Define the convpaint parameters\n",
    "layer_list = [[0], [0,2], [0,2,5]] # layers to use for convpaint (depending on the model chosen)\n",
    "scalings = [[1]]#, [1,2], [1,2,4], [1,2,4,8]] # scalings for convpaint (downscaling the image)\n",
    "model=\"vgg16\" # 'vgg16', 'efficient_netb0', 'single_layer_vgg16', 'single_layer_vgg16_rgb', 'dino_vits16'\n",
    "random_state = 123 # seed used for random forest classifier\n",
    "\n",
    "# Predictions\n",
    "for img_num in [500]:#range(0, 540, 10):#range(0, 10):\n",
    "    for bin in [0.1]: #bins:\n",
    "        for sc in [[1,2]]:#scalings:\n",
    "            for l in [[0]]:#layer_list:\n",
    "                print(f\"IMG {img_num}: bin {bin}, scalings {sc}, layers {l}\")\n",
    "                pred_cellpose_convpaint(folder_path, img_num, mode=mode, bin=bin, suff=s, layer_list=l, scalings=sc, model=model, random_state=random_state, save_res=False, show_res=True)\n",
    "                # get_cellpose_img_data(folder_path, img_num, load_img=True, load_gt=False, load_scribbles=False, mode=mode, bin=bin, suff=s, load_pred=False, pred_tag=\"convpaint\")\n",
    "                # pred_cellpose_convpaint(folder_path, img_num, mode=mode, bin=bin, suff=s, layer_list=layer_list, scalings=scalings, model=model, random_state=random_state, save_res=False, show_res=True)\n",
    "                # pred_cellpose_ilastik(folder_path, img_num, mode=mode, bin=bin, suff=s, save_res=False, show_res=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking apart ConvPaint..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./results/data/pred05_run02\"\n",
    "img_num = 500\n",
    "scribble_name = \"500_scribbles_all_00100_a.png\"\n",
    "\n",
    "image=np.array(Image.open(f\"{folder_path}/{img_num}_img.png\"))\n",
    "labels=np.array(Image.open(f\"{folder_path}/{scribble_name}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if image.ndim == 3 == 3 and image.shape[2] < 4:\n",
    "    image = np.moveaxis(image, 2, 0) # Convpaint expects (C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If some channel(s) contain(s) no values, remove them\n",
    "if image.ndim == 3 and image.shape[0] == 3:\n",
    "    # Check which channels contain values\n",
    "    image_r_is_active = np.count_nonzero(image[0])>0\n",
    "    image_g_is_active = np.count_nonzero(image[1])>0\n",
    "    image_b_is_active = np.count_nonzero(image[2])>0\n",
    "    num_active = sum((image_r_is_active, image_g_is_active, image_b_is_active))\n",
    "    # Remove the inactive channel(s)\n",
    "    if num_active < 3:\n",
    "        # If there are 2 active channels, only take those\n",
    "        image = image[[image_r_is_active, image_g_is_active, image_b_is_active]]\n",
    "        # If there is just one, only pick the one and reduce the dimensions\n",
    "        if num_active == 1:\n",
    "            image = np.squeeze(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the image\n",
    "from napari_convpaint.conv_paint_utils import compute_image_stats, normalize_image\n",
    "img_mean, img_std = compute_image_stats(image, ignore_n_first_dims=image.ndim-2)\n",
    "image = normalize_image(image, img_mean, img_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari_convpaint.conv_paint_utils import (Hookmodel, filter_image_multioutputs, get_features_current_layers, get_multiscale_features, train_classifier, predict_image, train_test_split)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# layer_list=[0,2,5]\n",
    "scalings=[1,2]\n",
    "model=\"vgg16\"\n",
    "random_state=123\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Hookmodel(model_name=model)\n",
    "# Ensure the layers are given as a list\n",
    "\n",
    "\n",
    "# if isinstance(layer_list, int):\n",
    "#     layer_list = [layer_list]\n",
    "# # Read out the layer names\n",
    "# all_layers = [key for key in model.module_dict.keys()]\n",
    "# layers = [all_layers[i] for i in layer_list]\n",
    "layers = ['features.0 Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))']#,\n",
    "        #   'features.2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))',\n",
    "        #   'features.5 Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))']\n",
    "\n",
    "\n",
    "\n",
    "# Register the hooks for the selected layers\n",
    "model.register_hooks(selected_layers=layers)\n",
    "\n",
    "\n",
    "\n",
    "# Get the features and targets\n",
    "features, targets = get_features_current_layers(\n",
    "    model=model, image=image, annotations=labels, scalings=scalings,\n",
    "    order=1, use_min_features=False, image_downsample=1)\n",
    "\n",
    "# # Create fake annotations (pretending the whole image is annotated), because conv_paint only returns features for annotated pixels    \n",
    "# fake_annot = np.ones(image.shape)\n",
    "# # Get features and targets using the fake annotations covering the full image\n",
    "# features, targets = get_features_current_layers(\n",
    "#     model=model, image=image, annotations=fake_annot, scalings=(1,), use_min_features=False, order=1)\n",
    "\n",
    "\n",
    "\n",
    "# Do RF training manually (copied from convpaint utils) to have access to seed/random_state:\n",
    "X, X_test, y, y_test = train_test_split(features, targets,\n",
    "                                        test_size=0.2,\n",
    "                                        random_state=42)\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state = random_state)\n",
    "random_forest.fit(X, y)\n",
    "\n",
    "# Predict on the image\n",
    "predicted = predict_image(\n",
    "    image, model, random_forest, scalings=scalings,\n",
    "    order=0, use_min_features=False, image_downsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = np.moveaxis(image, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QWindowsWindow::setGeometry: Unable to set geometry 853x493+3841-383 (frame: 869x532+3833-414) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY2\". Resulting geometry: 459x588+3833-424 (frame: 475x627+3825-455) margins: 8, 31, 8, 8 minimum size: 385x494 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=401,533 maxtrack=0,0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'scribbles' at 0x1cc36849f70>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = napari.Viewer()\n",
    "v.add_labels(predicted, name=\"pred\")\n",
    "v.add_image(image, name=\"image\")\n",
    "v.add_labels(labels, name=\"scribbles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes about the model usage of convpaint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### VGG16 model choices: 'vgg16', 'single_layer_vgg16', 'single_layer_vgg16_rgb' (others: 'efficient_netb0', 'dino_vits16')\n",
    "# if model_name == 'vgg16':\n",
    "#     self.model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "#     # self.transform =  models.VGG16_Weights.IMAGENET1K_V1.transforms()\n",
    "# elif model_name == 'efficient_netb0':\n",
    "#     self.model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "# elif model_name == 'single_layer_vgg16':\n",
    "#     self.model = load_single_layer_vgg16(keep_rgb=False)\n",
    "# elif model_name == 'single_layer_vgg16_rgb':\n",
    "#     self.model = load_single_layer_vgg16(keep_rgb=True)\n",
    "# elif model_name == 'dino_vits16':\n",
    "#     self.model = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ILASTIK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./cellpose_train_imgs/24-03-08_pred01\"\n",
    "img = np.array(Image.open(f\"{folder_path}/000_img.png\")) # NOTE: we need to take only one channel for Ilastik to work (so far)\n",
    "print(len(img.shape))\n",
    "# img = np.moveaxis(img, -1, 0)\n",
    "# print(img.shape)\n",
    "labels = np.array(Image.open(f\"{folder_path}/000_scribbles_all_00100_a.png\"))\n",
    "print(len(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = napari.Viewer()\n",
    "v.add_image(img, name=\"img\")\n",
    "v.add_labels(labels, name=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pixel_classification_ilastik(img, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.add_labels(pred, name=\"Ilastik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.add_labels(np.array(Image.open(f\"{folder_path}/000_convpaintCh1_all_0.1_a.png\")), name=\"Convpaint\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilastik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
