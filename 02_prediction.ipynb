{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import napari\n",
    "from PIL import Image\n",
    "\n",
    "from scribbles_creator import *\n",
    "from cellpose_data_handler import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define where the images are located and what data to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./cellpose_train_imgs/24-03-08_pred01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"all\"\n",
    "bins = [0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1]\n",
    "all_suff = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\"]\n",
    "suff = all_suff[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create predictions/segmentations on the cellpose dataset (with self-created scribbles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the convpaint parameters\n",
    "layer_list = [0] # layers to use for convpaint (depending on the model chosen)\n",
    "scalings = [1, 2] # scalings for convpaint (downscaling the image)\n",
    "model=\"vgg16\" # 'vgg16', 'efficient_netb0', 'single_layer_vgg16', 'single_layer_vgg16_rgb', 'dino_vits16'\n",
    "random_state = None # seed used for random forest classifier\n",
    "\n",
    "# Predictions\n",
    "for img_num in range(0, 10):\n",
    "    for bin in bins:\n",
    "        for s in suff:\n",
    "            print(f\"IMG {img_num}: {bin}_{s}\")\n",
    "            pred_cellpose_convpaint(folder_path, img_num, mode=mode, bin=bin, suff=s, layer_list=layer_list, scalings=scalings, model=model, random_state=random_state, save_res=True, show_res=False)\n",
    "            pred_cellpose_ilastik(folder_path, img_num, mode=mode, bin=bin, suff=s, save_res=True, show_res=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same cell but for testing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG 0: 0.01_a\n",
      "Active channels: R=True, G=True, B=False --> Removed 1 channel(s) --> shape: (2, 383, 512)\n",
      "IMG 189: 0.01_a\n",
      "Active channels: R=False, G=True, B=False --> Removed 2 channel(s) --> shape: (1, 209, 267)\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"./results/pred03_examples\"\n",
    "# folder_path = \"./cellpose_train_imgs\"\n",
    "\n",
    "mode = \"all\"\n",
    "bins = [0.1]#, 0.025, 0.05, 0.1, 0.25, 0.5, 1]\n",
    "all_suff = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\"]\n",
    "suff = all_suff[:1]\n",
    "\n",
    "# Define the convpaint parameters\n",
    "layer_list = [0] # layers to use for convpaint (depending on the model chosen)\n",
    "scalings = [1, 2] # scalings for convpaint (downscaling the image)\n",
    "model=\"single_layer_vgg16\" # 'vgg16', 'efficient_netb0', 'single_layer_vgg16', 'single_layer_vgg16_rgb', 'dino_vits16'\n",
    "random_state = 123 # seed used for random forest classifier\n",
    "\n",
    "# Predictions\n",
    "for img_num in (0,189):#range(0, 10):\n",
    "    for bin in [0.01]: #bins:\n",
    "        for s in [\"a\"]:#suff:\n",
    "            print(f\"IMG {img_num}: {bin}_{s}\")\n",
    "            # get_cellpose_img_data(folder_path, img_num, load_img=True, load_gt=False, load_scribbles=False, mode=mode, bin=bin, suff=s, load_pred=False, pred_tag=\"convpaint\")\n",
    "            pred_cellpose_convpaint(folder_path, img_num, mode=mode, bin=bin, suff=s, layer_list=layer_list, scalings=scalings, model=model, random_state=random_state, save_res=False, show_res=True)\n",
    "            pred_cellpose_ilastik(folder_path, img_num, mode=mode, bin=bin, suff=s, save_res=False, show_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### VGG16 model choices: 'vgg16', 'single_layer_vgg16', 'single_layer_vgg16_rgb' (others: 'efficient_netb0', 'dino_vits16')\n",
    "# if model_name == 'vgg16':\n",
    "#     self.model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "#     # self.transform =  models.VGG16_Weights.IMAGENET1K_V1.transforms()\n",
    "# elif model_name == 'efficient_netb0':\n",
    "#     self.model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "# elif model_name == 'single_layer_vgg16':\n",
    "#     self.model = load_single_layer_vgg16(keep_rgb=False)\n",
    "# elif model_name == 'single_layer_vgg16_rgb':\n",
    "#     self.model = load_single_layer_vgg16(keep_rgb=True)\n",
    "# elif model_name == 'dino_vits16':\n",
    "#     self.model = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ILASTIK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./cellpose_train_imgs/24-03-08_pred01\"\n",
    "img = np.array(Image.open(f\"{folder_path}/000_img.png\")) # NOTE: we need to take only one channel for Ilastik to work (so far)\n",
    "print(len(img.shape))\n",
    "# img = np.moveaxis(img, -1, 0)\n",
    "# print(img.shape)\n",
    "labels = np.array(Image.open(f\"{folder_path}/000_scribbles_all_00100_a.png\"))\n",
    "print(len(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = napari.Viewer()\n",
    "v.add_image(img, name=\"img\")\n",
    "v.add_labels(labels, name=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pixel_classification_ilastik(img, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.add_labels(pred, name=\"Ilastik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.add_labels(np.array(Image.open(f\"{folder_path}/000_convpaintCh1_all_0.1_a.png\")), name=\"Convpaint\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilastik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
